{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Olru90GqaX2"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "id": "uCWZnmdrqkWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "dFHyjPYKqr5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout"
      ],
      "metadata": {
        "id": "D45sbuBiqwSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.utils.image.image_dataset_from_directory(\n",
        "    directory = '/content/train', #path to train data folder where images for training are there\n",
        "    labels='inferred',\n",
        "    label_mode = 'int', #labels cat images as 0 and dog images as 1. so, when model predicts, it gives answer in 0 and 1.\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")\n",
        "\n",
        "#same for validation data images\n",
        "validation_ds = keras.utils.image.image_dataset_from_directory(\n",
        "    directory = '/content/test',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")"
      ],
      "metadata": {
        "id": "BMoxWESfrCYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "the function below converts the images into the array of floating numbers, and also scales the values between 0 and 1.\n",
        "'''\n",
        "def process(image,label):\n",
        "    image = tf.cast(image/255. ,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "#the above function is used for converting the images of train and test data into array of floating values between 0 and 1.\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ],
      "metadata": {
        "id": "o50Z0N_TrREc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "PG6hZXfNrV_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "898uXqZer__5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=10, validation_data=validation_ds)"
      ],
      "metadata": {
        "id": "IEnPLN-usFBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "7GFoiS74saKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = cv2.imread('/content/dog.jpg') #taking one dog image as the test image\n",
        "plt.imshow(test_img) #for just displaying the dog image"
      ],
      "metadata": {
        "id": "ndBb35r7scJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = cv2.resize(test_img,(256,256))\n",
        "#NOTE:- we always pass our images in form of batches. as we are just dealing with one test image right now, we wrote 1. also, as the image is rgb, we wrote 3.\n",
        "#all in all, we created a \"tensor of 256x256 rgb image with batch size 1\"\n",
        "test_input = test_img.reshape((1,256,256,3))"
      ],
      "metadata": {
        "id": "mKWvd95wsqoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test_input)\n",
        "#output = 1"
      ],
      "metadata": {
        "id": "uipumV6hst2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------DATA AUGMENTATION-----------"
      ],
      "metadata": {
        "id": "RSWcIbnTz3JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "KtEd0DyCz-7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('train/cat_18.jpg',target = (200,200))\n",
        "#we are just taking one image right now"
      ],
      "metadata": {
        "id": "IFxFe7sA0GjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "p_DNQfhb0S5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(img)\n",
        "#PIL.Image.Image"
      ],
      "metadata": {
        "id": "EvKv3ZvQ0Y3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#below object called datagen is used for image augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40, #rotates to 40 degrees\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2, #distorting the image\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True, #cat on left comes to right when we flip img horizonatally\n",
        ")"
      ],
      "metadata": {
        "id": "3RoERtv20eij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.img_to_array(img) #converting into array of values"
      ],
      "metadata": {
        "id": "66xz0Gm60sCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape\n",
        "#(200,200,3)"
      ],
      "metadata": {
        "id": "17R-YnBX0wVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch = img.reshape(1,200,200,3) #created a tensor"
      ],
      "metadata": {
        "id": "PT5X9glT1Ag9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "#when we are working with just one image, we use datagen.flow and if we work with multiple images stored in folder, we use datagen.flow_from_dir\n",
        "#save_to_dir creates a new folder called aug where all these 10 augmented images from a single image, gets stored.\n",
        "for output in datagen.flow(input_batch,batch_size=1,save_to_dir='aug'):\n",
        "  i+=1\n",
        "  if i == 10:\n",
        "    break"
      ],
      "metadata": {
        "id": "lntFuvFH1EtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch.shape"
      ],
      "metadata": {
        "id": "HEUkmZTh1Qzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#WHEN DEALING WITH WHOLE DIRECTORY OF IMAGES:-"
      ],
      "metadata": {
        "id": "Qm1BjuQQapOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "#we created seperate variables for train and validation data and initiated the type of transformation we want to apply.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "#for test data, only rescaling required. no additional transformations required.\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "#applying transformation to the train and test data, with 16 images at a time.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train',\n",
        "    target_size=(150,150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/test',\n",
        "    target_size=(150,150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "#the CNN MODEL comes here below where you add all the convolution layers and fully connected layers\n",
        "#compile model\n",
        "#train model:-\n",
        "model.fit(train_generator, epochs=25, validation_data=validation_generator)\n",
        "'''\n",
        "we only use the transformed images for training and leave the original images aside.\n",
        "'''"
      ],
      "metadata": {
        "id": "XQa_kgtVat6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}